{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid, relu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "np.random.seed(2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "with open('data/sem_items_new.txt','r') as fid:\n",
    "    names_items = np.array([l.strip() for l in fid.readlines()])\n",
    "with open('data/sem_relations_new.txt','r') as fid:\n",
    "    names_relations = np.array([l.strip() for l in fid.readlines()])\n",
    "with open('data/sem_attributes_new.txt','r') as fid:\n",
    "    names_attributes = np.array([l.strip() for l in fid.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of items:\n",
      "Pine,Oak,Rose,Daisy,Robin,Canary,Sunfish,Salmon,Turtle,Crocodile\n",
      "\n",
      "List of relations:\n",
      "ISA,Is,Can,Has\n",
      "\n",
      "List of attributes:\n",
      "Living thing,Plant,Animal,Tree,Flower,Bird,Fish,Reptile,Pine,Oak,Rose,Daisy,Robin,Canary,Sunfish,Salmon,Turtle,Crocodile,Pretty,Big,Living,Green,Red,Yellow,Slow,Grow,Move,Swim,Fly,Sing,Skin,Roots,Leaves,Bark,Branch,Petals,Wings,Feathers,Gills,Scales,Backbone,Produce Eggs,Shell\n"
     ]
    }
   ],
   "source": [
    "nobj = len(names_items)\n",
    "nrel = len(names_relations)\n",
    "nattributes = len(names_attributes)\n",
    "print('List of items:')\n",
    "print(*names_items,sep=',')\n",
    "print(\"\\nList of relations:\")\n",
    "print(*names_relations,sep=',')\n",
    "print(\"\\nList of attributes:\")\n",
    "print(*names_attributes,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input pattern:\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      "Example output pattern:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1]\n",
      "\n",
      "Which encodes...\n",
      "Item ['Turtle']\n",
      "Relation ['Has']\n",
      "Attributes ['Skin' 'Backbone' 'Shell']\n"
     ]
    }
   ],
   "source": [
    "item_display_ind = 35 # can change, just represents index of input data to show as example.\n",
    "\n",
    "D = np.loadtxt('data/sem_data_new.txt')\n",
    "input_pats = D[:,:nobj+nrel]\n",
    "input_pats = torch.tensor(input_pats,dtype=torch.float)\n",
    "output_pats = D[:,nobj+nrel:]\n",
    "output_pats = torch.tensor(output_pats,dtype=torch.float)\n",
    "N = input_pats.shape[0] # number of training patterns\n",
    "\n",
    "\n",
    "\n",
    "input_v = input_pats[item_display_ind,:].numpy().astype('bool')\n",
    "output_v = output_pats[item_display_ind,:].numpy().astype('bool')\n",
    "print('Example input pattern:')\n",
    "print(input_v.astype('int'))\n",
    "print('Example output pattern:')\n",
    "print(output_v.astype('int'))\n",
    "print(\"\")\n",
    "print(\"Which encodes...\")\n",
    "print('Item ',end='')\n",
    "print(names_items[input_v[:nobj]])\n",
    "print('Relation ',end='')\n",
    "print(names_relations[input_v[nobj:]])\n",
    "print('Attributes ',end='')\n",
    "print(names_attributes[output_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, rep_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        # Input\n",
    "        #  rep_size : number of hidden units in \"Representation Layer\"\n",
    "        #  hidden_Size : number of hidden units in \"Hidden Layer\"\n",
    "        #\n",
    "        # TODO : YOUR CODE GOES HERE\n",
    "        self.i2rep = nn.Linear(nobj,rep_size)\n",
    "        self.all2h = nn.Linear(rep_size+nrel,hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size,nattributes)\n",
    "        self.sigmoid = torch.sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defines forward pass for the network on input patterns x\n",
    "        #\n",
    "        # Input can take these two forms:\n",
    "        #\n",
    "        #   x: [nobj+nrel 1D Tensor], which is a single input pattern as a 1D tensor\n",
    "        #      (containing both object and relation 1-hot identifier) (batch size is B=1)\n",
    "        #   OR\n",
    "        #   x : [B x (nobj+nrel) Tensor], which is a batch of B input patterns (one for each row)\n",
    "        #\n",
    "        # Output\n",
    "        #   output [B x nattribute Tensor], which is the output pattern for each input pattern B on the Attribute Layer\n",
    "        #   hidden [B x hidden_size Tensor], which are activations in the Hidden Layer\n",
    "        #   rep [B x rep_size Tensor], which are the activations in the Representation LAyer\n",
    "        x = x.view(-1,nobj+nrel) # reshape as size [B x (nobj+nrel) Tensor] if B=1\n",
    "        x_item = x[:,:nobj] # input to Item Layer [B x nobj Tensor]\n",
    "        x_rel = x[:,nobj:] # input to Relation Layer [B x nrel Tensor]\n",
    "        \n",
    "        rep = self.i2rep(x_item)\n",
    "        rep = relu(rep)\n",
    "        to_hidden = torch.cat((rep,x_rel),1)\n",
    "        hidden = self.all2h(to_hidden)\n",
    "        hidden = relu(hidden)\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.sigmoid(output)\n",
    "        \n",
    "        return output, hidden, rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tsize mismatch for all2h.weight: copying a param with shape torch.Size([15, 12]) from checkpoint, the shape in current model is torch.Size([43, 12]).\n\tsize mismatch for all2h.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([43]).\n\tsize mismatch for h2o.weight: copying a param with shape torch.Size([43, 15]) from checkpoint, the shape in current model is torch.Size([43, 43]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-955c49990ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m             hidden_size=len(loaded_model['model_state_dict']['h2o.bias']))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmynet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tsize mismatch for all2h.weight: copying a param with shape torch.Size([15, 12]) from checkpoint, the shape in current model is torch.Size([43, 12]).\n\tsize mismatch for all2h.bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([43]).\n\tsize mismatch for h2o.weight: copying a param with shape torch.Size([43, 15]) from checkpoint, the shape in current model is torch.Size([43, 43])."
     ]
    }
   ],
   "source": [
    "loaded_model = torch.load('trained_model.pt')\n",
    "\n",
    "mynet = Net(rep_size=len(loaded_model['model_state_dict']['i2rep.bias']),\n",
    "            hidden_size=len(loaded_model['model_state_dict']['h2o.bias']))\n",
    "\n",
    "mynet.load_state_dict(loaded_model['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('i2rep.weight',\n",
       "              tensor([[-1.6697e-01, -1.0548e-01, -8.5725e-02, -2.1847e-01, -3.1227e-01,\n",
       "                        7.0004e-02, -3.0399e-01, -2.0083e-01, -1.5825e-01, -1.9332e-01],\n",
       "                      [ 6.8134e-02, -2.7301e-01,  2.7604e-01, -2.7800e-01,  1.3054e-01,\n",
       "                       -2.0587e-02,  2.1805e-01, -2.4378e-01, -1.8679e-01,  5.9163e-02],\n",
       "                      [-3.1202e-01,  1.6521e-01,  2.2545e-01,  2.4024e-01, -1.9706e-01,\n",
       "                       -2.2313e-01, -2.6819e-01, -6.1272e-02, -1.8869e-03, -1.0969e-01],\n",
       "                      [-2.7036e-01, -2.9644e-01, -1.5001e-01, -3.0799e-01, -2.6625e-01,\n",
       "                        1.7465e-02, -8.0025e-02, -2.0765e-01, -1.6567e-01, -1.7424e-01],\n",
       "                      [ 5.3897e-01, -7.4094e-02, -7.4800e-01, -8.7271e-01, -1.3754e-01,\n",
       "                        1.7907e-01,  1.0643e+00,  1.1945e+00, -8.3859e-01, -1.8213e-01],\n",
       "                      [ 1.8797e+00,  2.3156e+00,  1.0869e+00,  1.3901e+00, -1.3932e+00,\n",
       "                       -1.4373e+00, -4.1240e-02, -9.1738e-02, -8.1123e-01, -5.4678e-01],\n",
       "                      [-4.7671e-01, -3.9323e-01,  7.8948e-01,  9.4457e-01, -1.7418e-01,\n",
       "                       -4.9050e-01, -9.5691e-01, -8.7940e-01,  1.5580e+00,  1.2727e+00],\n",
       "                      [ 1.0428e-01, -3.7204e-01,  1.1578e+00,  4.6606e-01, -4.4048e-01,\n",
       "                       -4.6219e-01, -2.7782e-01,  1.0824e-01, -4.6140e-01,  1.2025e-01]])),\n",
       "             ('i2rep.bias',\n",
       "              tensor([-0.2625, -0.2763, -0.2407, -0.2594,  0.9666,  1.4363,  1.0491,  0.4617])),\n",
       "             ('all2h.weight',\n",
       "              tensor([[-3.0122e-02, -2.5284e-01,  1.6458e-01,  1.7562e-01, -6.4521e-01,\n",
       "                        6.2856e-01,  1.9673e+00, -7.6312e-04,  2.2826e+00, -8.3851e-01,\n",
       "                        5.8665e-01, -5.9516e-01],\n",
       "                      [ 5.4983e-02, -5.1910e-02, -2.8807e-01,  1.5493e-01, -2.5476e-01,\n",
       "                       -2.8548e-01, -2.4176e-02, -2.3961e-01, -1.6723e-01, -2.8509e-01,\n",
       "                        7.2094e-02, -1.9683e-01],\n",
       "                      [ 1.2783e-01, -8.0379e-02, -2.0620e-01,  8.3140e-02,  5.2329e-01,\n",
       "                        1.9311e+00, -4.1456e-01,  1.2929e-01,  1.2302e+00, -5.0749e-01,\n",
       "                       -1.1651e+00,  5.6836e-01],\n",
       "                      [ 8.4043e-02,  1.2504e-01,  1.5374e-01,  6.0748e-02,  7.1840e-01,\n",
       "                        2.1109e+00, -1.0551e+00, -9.6536e-02, -1.7300e-01, -4.2241e-01,\n",
       "                        3.0034e-01,  6.4442e-01],\n",
       "                      [-1.3902e-01,  2.2566e-01,  2.8947e-02, -1.3866e-01, -7.8472e-02,\n",
       "                        9.6158e-01,  9.1966e-01,  4.6136e-01,  1.3236e-01,  2.6906e-02,\n",
       "                        1.2328e+00, -1.1614e+00],\n",
       "                      [ 1.9165e-01,  2.6078e-01, -1.4383e-01, -1.5455e-01,  9.3991e-01,\n",
       "                        5.8592e-02, -6.0497e-01, -7.3678e-01,  3.7480e-01,  7.8640e-01,\n",
       "                       -2.5793e-01,  5.7230e-01],\n",
       "                      [ 1.1176e-01, -1.0891e-02, -2.6412e-02, -1.7521e-02,  1.5459e+00,\n",
       "                        6.5454e-02, -8.5286e-01, -5.9699e-03,  7.1182e-01,  6.2325e-01,\n",
       "                        2.1327e+00, -8.1451e-01],\n",
       "                      [ 1.3272e-01, -6.1714e-02,  1.6274e-01,  1.6897e-01,  3.5468e-01,\n",
       "                       -4.3914e-01, -3.6013e-01, -5.0659e-01,  2.2515e+00,  5.6379e-02,\n",
       "                       -4.4750e-01,  2.8727e-01],\n",
       "                      [-9.0775e-03, -1.8543e-01, -1.5890e-01, -1.4290e-01, -4.8202e-01,\n",
       "                        5.4068e-01,  4.2978e-01, -3.1375e-01, -9.7933e-01, -8.3838e-02,\n",
       "                       -4.9658e-01,  3.1908e+00],\n",
       "                      [-4.7876e-02, -1.4973e-01,  1.1156e-01,  5.6159e-02, -4.2076e-02,\n",
       "                       -2.4411e-01, -1.1284e-01,  2.3889e-01,  4.4558e-02, -6.2892e-02,\n",
       "                       -1.0565e-01, -2.1301e-01],\n",
       "                      [-1.3590e-01, -2.0135e-01, -1.3366e-01,  1.1102e-01,  2.8364e-01,\n",
       "                       -3.8477e-01,  2.5631e-01, -2.4200e-01,  1.3729e+00,  2.0873e+00,\n",
       "                       -1.2241e+00, -4.2654e-01],\n",
       "                      [ 2.7024e-01,  1.8074e-01,  7.4617e-02, -1.8082e-02, -8.7601e-01,\n",
       "                        2.4562e+00, -4.5963e-02,  6.6764e-01,  5.8068e-01,  1.1570e+00,\n",
       "                       -1.3082e+00, -1.1124e+00],\n",
       "                      [ 2.0844e-01, -1.5900e-01, -1.7257e-01,  2.5600e-01, -2.9494e-01,\n",
       "                       -1.3416e-01,  1.0912e+00, -5.6969e-01, -7.2821e-01,  1.7244e+00,\n",
       "                        1.9560e+00,  2.8425e-01],\n",
       "                      [ 2.5013e-02,  2.0694e-01, -2.7790e-01,  2.2014e-01, -2.8844e-01,\n",
       "                        1.6328e+00,  4.7220e-01,  8.7398e-01, -1.2583e+00,  1.9878e+00,\n",
       "                       -2.9098e-01, -3.6466e-01],\n",
       "                      [-1.7367e-01, -1.8485e-02,  2.7306e-01,  1.7733e-01, -1.3255e-01,\n",
       "                       -4.8029e-01, -3.1277e-02, -2.6971e-01,  7.4756e-03,  1.1688e-01,\n",
       "                        8.7188e-01, -7.3369e-02]])),\n",
       "             ('all2h.bias',\n",
       "              tensor([ 0.8853, -0.0252,  0.1541,  0.6617,  0.7128,  1.2604,  2.4036,  1.3219,\n",
       "                       1.9751, -0.0560,  1.4684, -0.4728,  2.6666,  0.3558,  0.2127])),\n",
       "             ('h2o.weight',\n",
       "              tensor([[ 7.9984e-01, -2.4502e-01,  5.0597e-01, -2.2136e-01, -6.0662e-02,\n",
       "                       -3.4582e-01, -1.1568e-01,  9.2475e-01, -6.6797e-01,  1.6081e-01,\n",
       "                        4.7259e-01,  5.8309e-01, -9.8424e-01, -8.7316e-01, -1.4915e-02],\n",
       "                      [ 5.2232e-01, -1.3744e-01,  6.5389e-01, -1.2440e-01, -6.3204e-02,\n",
       "                       -4.5635e-01, -5.9461e-01,  1.9631e-01, -1.0468e+00, -1.1669e-01,\n",
       "                       -5.8230e-01,  6.7557e-01, -1.3201e+00,  1.2165e-01,  2.2007e-02],\n",
       "                      [ 8.7582e-01, -3.3144e-03,  2.4302e-01, -3.9295e-01, -3.9841e-01,\n",
       "                       -1.7954e-01,  2.0969e-01,  1.0105e+00, -8.6711e-01, -2.0843e-01,\n",
       "                        4.9872e-01, -3.3361e-01, -8.7289e-01, -8.7992e-01, -3.1482e-01],\n",
       "                      [-1.8303e-01, -9.1537e-02,  6.5587e-01,  1.5223e-01, -3.2359e-01,\n",
       "                       -1.0578e-01, -3.4315e-01, -7.9801e-02, -9.1847e-01,  1.7055e-01,\n",
       "                       -4.0407e-01,  7.1927e-01, -1.2750e+00, -1.2722e-01, -2.0679e-02],\n",
       "                      [ 5.6000e-01, -2.6624e-01,  3.0893e-01, -3.7146e-01,  2.7115e-01,\n",
       "                       -7.7842e-01, -8.7195e-01, -4.2384e-01, -7.1124e-01, -2.1510e-01,\n",
       "                       -1.6005e-01,  4.7331e-01, -1.0346e+00, -4.3104e-02,  1.9704e-01],\n",
       "                      [ 1.4982e-01,  3.2970e-03, -2.4316e-01, -7.6173e-01, -3.6052e-01,\n",
       "                        2.0522e-01,  8.5203e-02,  1.0517e+00, -7.2802e-01,  1.3556e-01,\n",
       "                        1.5463e-01, -5.6191e-01, -5.3487e-01, -5.7907e-01,  4.5201e-02],\n",
       "                      [-6.2395e-01,  8.0278e-02,  5.3495e-01,  1.5189e-01, -4.1007e-01,\n",
       "                        1.1373e-01,  2.6856e-01,  4.4059e-01, -8.7249e-01, -7.0576e-02,\n",
       "                        8.7555e-02,  1.0235e-01, -1.2265e+00, -5.5975e-01, -2.3625e-01],\n",
       "                      [ 8.6493e-01,  6.4788e-02, -1.7765e-01, -5.6937e-01,  2.5770e-01,\n",
       "                       -4.3307e-01, -1.0461e+00,  2.2247e-01, -6.7897e-01,  1.6011e-01,\n",
       "                        2.4535e-01,  2.0242e-02, -3.7202e-01, -5.9592e-01, -8.7567e-02],\n",
       "                      [-8.6041e-02, -3.8859e-02, -1.9712e-01, -1.8292e-01, -1.9000e-01,\n",
       "                       -3.4555e-01, -3.6239e-01,  1.4665e-01, -4.1546e-01,  2.0006e-01,\n",
       "                       -5.7813e-02, -6.3876e-02, -4.8446e-01, -2.5723e-01,  7.4980e-02],\n",
       "                      [-1.8747e-01,  3.8388e-02,  9.7336e-02, -1.6647e-01, -2.6309e-01,\n",
       "                       -2.0900e-01, -1.6776e-02, -1.4267e-01, -4.0948e-01, -4.3254e-02,\n",
       "                       -1.3848e-01, -4.2591e-02, -4.4809e-01,  3.3151e-02, -1.9088e-01],\n",
       "                      [ 3.2387e-01, -3.5859e-02,  1.4983e-01, -2.5730e-01,  2.4720e-01,\n",
       "                       -3.7870e-01, -5.5524e-01, -2.6404e-01, -6.2555e-01,  2.1911e-02,\n",
       "                       -2.4255e-01,  3.0454e-01, -7.8338e-01, -2.7198e-02,  1.0892e-01],\n",
       "                      [ 1.7760e-01,  1.1859e-01,  1.6204e-01, -9.8444e-02,  1.9523e-01,\n",
       "                       -4.7215e-01, -7.5866e-01,  1.1138e-01, -4.8875e-01,  1.5511e-01,\n",
       "                       -1.9002e-01,  2.4904e-01, -5.2272e-01, -4.2515e-02, -4.7973e-02],\n",
       "                      [ 2.2962e-01,  1.5891e-01, -2.3254e-01, -6.0489e-01, -1.9850e-01,\n",
       "                        1.6657e-01, -1.1801e-01,  3.7888e-01, -2.9049e-01, -7.6127e-02,\n",
       "                        1.3820e-01, -5.6770e-02, -5.0190e-01, -5.5773e-01, -2.4481e-01],\n",
       "                      [-2.0805e-02, -4.3537e-02, -1.3983e-01, -3.3550e-01, -3.2360e-01,\n",
       "                       -1.3473e-02,  8.9157e-02,  4.1012e-01, -6.3666e-01,  1.8964e-01,\n",
       "                        3.7163e-01, -3.1966e-01, -5.2782e-01, -3.6003e-01, -2.3541e-01],\n",
       "                      [-3.0256e-01,  1.5227e-01,  3.0022e-01, -1.5570e-02, -1.8412e-02,\n",
       "                        1.2251e-01,  5.6148e-02,  1.1649e-01, -5.3519e-01,  7.4446e-02,\n",
       "                       -4.1103e-02, -1.7603e-02, -8.0832e-01, -3.3742e-01,  9.1438e-02],\n",
       "                      [-3.5101e-01,  1.3620e-01,  3.5601e-01, -4.5042e-02, -2.2793e-01,\n",
       "                        8.0715e-02,  2.0384e-01,  6.6088e-02, -6.2837e-01,  1.8534e-01,\n",
       "                        4.0433e-02,  9.3459e-02, -8.8774e-01, -3.2317e-01,  1.3354e-01],\n",
       "                      [ 5.7031e-01, -2.4612e-01, -1.5386e-01, -7.3736e-01, -2.1000e-02,\n",
       "                       -3.2406e-01, -7.4433e-01,  7.3257e-02, -3.1745e-01, -2.4506e-01,\n",
       "                        1.1783e-02, -1.9194e-02, -3.7637e-01, -2.9724e-01, -2.0442e-01],\n",
       "                      [ 4.6170e-01,  2.0471e-01,  8.4873e-02, -4.9267e-01,  7.5526e-02,\n",
       "                       -7.6906e-02, -2.7810e-01, -1.0372e-01, -5.5096e-01,  1.2685e-01,\n",
       "                       -1.1285e-01,  1.8365e-01, -4.0581e-01, -4.3162e-01, -2.5254e-01],\n",
       "                      [-4.2854e-01,  1.4180e-01, -3.3710e-01, -7.1228e-01, -5.5182e-02,\n",
       "                       -6.1030e-01, -7.2755e-01, -2.8850e-01, -5.0927e-01,  1.4622e-01,\n",
       "                       -1.6572e-01,  8.3400e-01, -2.9243e-01,  9.8361e-01,  1.8000e-01],\n",
       "                      [-1.1131e+00,  1.8267e-01,  1.1045e-01,  2.3661e-02, -3.1230e-01,\n",
       "                       -3.0166e-02, -2.1785e-01, -6.4901e-01, -7.5963e-01,  1.8107e-02,\n",
       "                       -1.0314e-01,  1.0109e+00, -4.8186e-01,  4.2051e-01, -3.9406e-02],\n",
       "                      [-1.1452e+00, -2.2731e-02, -4.0628e-01, -6.0541e-01, -1.5107e-01,\n",
       "                        1.3722e-01, -2.4488e-01, -2.6815e-01, -7.3405e-01, -1.1739e-01,\n",
       "                        1.0526e+00,  7.4942e-01,  3.1130e-01,  1.0293e+00, -5.0849e-02],\n",
       "                      [-2.2389e-01, -2.4496e-02, -1.3046e-02, -6.2754e-01,  1.1397e-01,\n",
       "                        4.2555e-02, -2.0261e-01, -6.9546e-01, -5.8385e-01,  1.4309e-01,\n",
       "                        3.0149e-01, -3.8347e-02, -1.9935e-01,  5.4605e-01, -8.5549e-03],\n",
       "                      [-7.2041e-01, -1.9158e-01, -2.9637e-01, -6.3223e-01, -1.3597e-01,\n",
       "                       -3.4846e-01,  1.7208e-01,  1.2728e-01, -4.6446e-01,  2.0586e-01,\n",
       "                        2.9074e-01,  3.2260e-01, -3.0153e-01,  9.2872e-01, -2.6068e-01],\n",
       "                      [-7.3297e-01, -1.8346e-01, -6.1128e-01, -1.0556e-01, -3.2686e-01,\n",
       "                        2.0671e-01, -1.1296e-01,  1.2471e-01, -4.9572e-01,  1.7705e-02,\n",
       "                        3.4544e-01,  4.2483e-01, -1.3503e-01,  5.2798e-01,  8.8562e-02],\n",
       "                      [ 1.9409e-02, -5.8222e-02, -7.4982e-01, -5.2326e-01, -7.8847e-02,\n",
       "                       -2.1012e-01, -7.5599e-01, -4.1298e-01, -3.0084e-01,  5.4208e-03,\n",
       "                        3.2895e-01,  1.8798e-01,  6.9969e-02,  2.1485e-01, -1.9035e-01],\n",
       "                      [ 2.1543e-01,  3.0415e-02, -7.9765e-01,  5.8664e-01,  9.1461e-01,\n",
       "                       -5.4223e-01,  7.6145e-01, -8.7903e-01, -7.4883e-01, -1.2940e-01,\n",
       "                       -1.3384e+00, -6.1155e-01,  3.1673e-01, -2.3707e-01, -7.7620e-02],\n",
       "                      [ 4.7124e-02, -1.5921e-01, -7.9912e-01, -6.9737e-02,  4.4737e-01,\n",
       "                       -3.6838e-01,  8.2555e-01, -6.2060e-01, -6.3560e-01, -1.2164e-01,\n",
       "                       -1.0220e+00, -1.0346e+00,  3.2873e-01, -5.1550e-01,  1.7903e-01],\n",
       "                      [-1.7041e-02,  1.6359e-02, -4.7405e-01,  5.6108e-01,  4.8607e-01,\n",
       "                       -4.1375e-01,  1.9245e-01, -4.4913e-01, -6.0858e-01,  9.5763e-02,\n",
       "                       -8.1557e-01, -1.2340e+00, -3.2650e-01,  4.4953e-01, -2.1646e-01],\n",
       "                      [-3.3945e-01, -2.1935e-01, -8.1692e-01, -4.4133e-01, -9.0264e-02,\n",
       "                       -1.5182e-01,  5.7390e-01, -1.5561e-02, -5.6816e-01, -2.5377e-03,\n",
       "                       -6.3460e-01, -4.0497e-01,  2.9104e-01, -8.8014e-01,  5.9308e-01],\n",
       "                      [-2.5689e-01, -1.6751e-01, -5.4448e-01, -2.4529e-01, -1.8925e-01,\n",
       "                       -1.6585e-02,  3.9831e-01, -2.4648e-01, -4.3830e-01, -2.3908e-01,\n",
       "                       -4.2031e-01,  3.2462e-02, -3.1022e-02, -4.3688e-01,  4.3108e-01],\n",
       "                      [-4.8422e-01, -2.3637e-02,  2.2249e-01, -6.3985e-02, -8.1854e-01,\n",
       "                        1.2583e-01, -5.7040e-01,  3.7313e-02,  1.5083e+00, -2.3762e-01,\n",
       "                       -2.1235e-01, -1.3462e+00, -1.8570e-01, -1.7299e-01,  9.5605e-02],\n",
       "                      [-3.0460e-01,  3.4359e-03,  2.8120e-01,  4.0099e-01, -4.8516e-01,\n",
       "                       -4.4665e-01, -1.2537e+00, -7.0514e-01,  6.2434e-01, -2.1868e-01,\n",
       "                       -1.0137e+00,  5.6387e-01, -7.2271e-01,  5.6777e-02, -2.7223e-02],\n",
       "                      [-2.2340e-01,  4.8389e-02,  3.0938e-01, -8.6225e-02, -1.8571e-01,\n",
       "                       -5.7948e-01, -1.2750e+00, -5.9564e-01,  5.5375e-01,  2.7911e-02,\n",
       "                       -7.6576e-01,  5.1481e-01, -7.0306e-01,  1.1679e-01, -2.9157e-01],\n",
       "                      [-7.0238e-01,  1.5536e-01,  4.8314e-01,  5.9349e-01, -3.5730e-01,\n",
       "                       -5.1810e-02, -8.0334e-01, -6.6859e-01,  7.1798e-02,  1.4864e-01,\n",
       "                       -5.5940e-01,  2.4955e-01, -9.1178e-01, -3.7434e-02, -2.4620e-02],\n",
       "                      [-6.9655e-01, -1.5021e-02,  2.8806e-01,  5.5126e-01, -5.3691e-01,\n",
       "                       -1.2995e-01, -5.5833e-01, -4.6023e-01,  1.7927e-01,  1.1649e-02,\n",
       "                       -8.4797e-01,  4.5732e-01, -9.7422e-01,  4.9806e-02, -2.7162e-01],\n",
       "                      [ 8.5849e-02,  1.1935e-01, -2.4542e-02, -1.1399e-02, -2.7184e-01,\n",
       "                       -8.5470e-01, -1.1902e+00, -5.3640e-01,  3.9788e-01,  7.2830e-03,\n",
       "                       -6.5523e-01,  2.5027e-01, -5.4223e-01,  2.7807e-01,  1.9717e-01],\n",
       "                      [-6.0305e-01,  2.1893e-01, -5.2899e-01, -2.4552e-01, -7.8699e-01,\n",
       "                        3.4311e-01, -4.5815e-01,  3.6155e-01,  7.9825e-01, -1.2101e-01,\n",
       "                       -6.5891e-03, -4.8061e-01, -4.4055e-02, -8.1535e-01, -5.5301e-02],\n",
       "                      [-6.8722e-01, -2.1626e-01, -3.2990e-01, -5.4920e-01, -9.6002e-01,\n",
       "                        9.7464e-02, -2.3785e-01,  3.1409e-01,  8.6654e-01,  3.5471e-02,\n",
       "                       -2.1968e-01, -4.9975e-01, -2.8573e-02, -5.6289e-01, -1.7581e-01],\n",
       "                      [-1.0774e+00, -7.7273e-02,  4.9677e-01,  2.9881e-01, -3.0007e-01,\n",
       "                        4.6673e-01, -1.5983e-01, -4.4413e-02,  2.1538e-01, -1.2018e-01,\n",
       "                       -4.1020e-01, -6.1983e-01, -9.5067e-01, -2.0903e-01,  1.0004e-01],\n",
       "                      [-1.1497e+00, -1.9637e-01,  5.5335e-01,  4.8643e-01, -5.6398e-01,\n",
       "                        2.2431e-01, -8.8144e-02, -2.4476e-01,  1.0576e-01, -1.2738e-03,\n",
       "                       -4.1200e-01, -5.8955e-01, -6.7998e-01, -3.4154e-01,  8.5133e-02],\n",
       "                      [ 2.5682e-01,  5.4052e-03,  7.9159e-02, -4.6935e-01, -1.4156e-01,\n",
       "                       -1.3666e-01, -1.3364e+00, -3.6557e-01,  6.1719e-01,  2.5241e-01,\n",
       "                       -3.7478e-01, -8.2457e-01, -9.3041e-02, -6.6065e-03, -5.6804e-02],\n",
       "                      [ 1.1354e-01,  1.7911e-03, -1.1478e+00, -7.1539e-01,  4.7040e-01,\n",
       "                       -3.9625e-01,  3.5055e-01, -2.0503e-01, -5.2183e-01, -1.7199e-01,\n",
       "                       -7.1377e-01, -6.2006e-01,  4.6079e-01, -7.0179e-01,  5.3483e-01],\n",
       "                      [ 5.9562e-02, -3.8195e-02, -1.1783e-01, -5.0546e-01, -4.3596e-02,\n",
       "                       -3.3889e-01, -7.6974e-01,  1.2370e-02,  3.4420e-01, -1.7860e-01,\n",
       "                       -3.9985e-01, -3.8126e-01, -7.3282e-02, -9.2219e-02, -2.8057e-01]])),\n",
       "             ('h2o.bias',\n",
       "              tensor([-0.2236, -0.8583,  0.2176, -0.3650, -0.3106, -0.2127, -0.1857, -0.6463,\n",
       "                      -0.1817, -0.5229, -0.3518, -0.3678, -0.3455, -0.3913, -0.1286, -0.5047,\n",
       "                      -0.2034, -0.3311, -0.8178, -0.8830, -0.2189, -0.1812, -0.2829, -0.3314,\n",
       "                      -0.3843, -0.4160, -0.0469, -0.0930, -0.0491, -0.0393, -0.0869, -0.5648,\n",
       "                      -0.5068, -0.3432, -0.6486, -0.4255, -0.1996,  0.0582, -0.2647, -0.2203,\n",
       "                      -0.4124, -0.4763, -0.2570]))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
